============
* Stage 19 *
============

Description
-----------
Prepare data before uploading to ElasticSearch:
 * turn JSON keys to lower case
 * generate JSON with index information

Use ./run.sh to run stage with common configuration from
  /Utils/Elasticsearch/config/es

Input
-----
Expects data in JSON format with special fields.
Required:
* '_id' (ES record identifier);
* '_type' (ES record type).

Optional:
* '_parent' (ES identifier for parent type record).

Output
------
JSON documents, one document per line:
{{{
 <index info>
 <data>
 <index info>
 <data>
 ...
}}}

TODO
----
Currently, it operates as if one line was one message (piece of information).
For input it is OK, but for output it would be better to take <index info> and
  <data> JSON documents together, as one message. I don`t know where it will
  be critical for now, but something tells me that it will.
This task requires accurate EOMessage and EOProcess markers handling (see the
  `kafka-dataflow-markers` branch).

Samples
-------
The 'output' directory contains two pairs of samples:

2016 data:
tasks2016.ndjson (from 017's 2016 sample)
datasets2016.ndjson (from 095's 2016 sample)

2018 data:
tasks2018.ndjson (from 017's 2018 sample)
datasets2018.ndjson (from 095's 2018 sample)

tasks* is the tasks' and input datasets' metadata.
datasets* is the output datasets' metadata.
