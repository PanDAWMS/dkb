=========================
* Stage 60 (last stage) *
=========================

Table of contents:
I.  Description -- stage descriplion
II. Kafka style -- how to use with Kafka stage

***

I. Description
==============

Upload data to Virtuoso as:
- TTL files
- SPARQL query files

To avoid explicit specifying username/password in the command line, one can
store them in file ./.credentials:
{{{
username
password
}}}

WARNING: SPARQL query files should not be of size > ~1M (it's a rule of thumb, though). Files of a greater sizes produces SPARQL error like this:
{{{
The length of generated SQL text has exceeded 10000 lines of code.
}}}

Input data
---

Example:
1) TTL
{{{
<ObjectID> a <ObjectType> .
<ObjectID> <Property> Value .
}}}

2) SPARQL statements

Make sure that there's ';' separator between statements.

Example:
{{{
WITH $GraphIRI
INSERT {
  $TRIPLE_1 .
  $TRIPLE_2 .
};
WITH $GraphIRI
INSERT {
  ?a $PROP_A ?b
}
WHERE
{
  VALUES ( ?a ?c ) {
    ( $ValA1 $ValC1 )
    ( $ValA2 $ValC2 )
  }
  ?b $PROP_B ?c .
}
}}}


Output files
---

None.

II. Kafka style
===============

As a step of Kafka data flow it is a Sink stage.

To write data into Virtuoso via Kafka one should perform the following steps:
- create Kafka topic(s) named "*-ttl" and/or "*-sparql"
    (e.g. "dataset-metadata-ttl" and "dataset-metadata-sparql")

- add name of the newly added topic(s) into the corressponding config file(s)
    (../000_kafka/config/virtuoso-{ttl|sparql}-sink.properties)
    {{{
      TYPE=ttl
      NEW_TOPIC='dataset-metadata-ttl'
      sed -i.bak -e"s/^topics=.*$/\0,$NEW_TOPIC/" \
        ../000_kafka/config/virtuoso-$TYPE-sink.properties
    }}}

- restart virtuoso sink by typing:
    {{{
    ../000_kafka/run.sh VirtuosoSink restart
    }}}

- start writing your data into corresponding topics

