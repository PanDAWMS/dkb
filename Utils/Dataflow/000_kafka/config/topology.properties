#
# Topology configuration file for Kafka Streams Application
#
# Example file
# Configufing topology:
#
#   KAFKA TOPICS ||==================|| EXTERNAL PROGRAMM ||========================|| KAFKA TOPICS
#                ||                   \\                 //                         ||
#           test1 >----                 =======|==|======                           ||
#                ||    \                       |  |                                 ||
#           test2 >--------> (source1) >----> ( p1 ) >---------------> (sink1) >----> my-sink-topic
#                ||                                     \                           ||
# my-source-topic >--------> (MySource) >------------------> (p2) >--> (sink2) >----> another-sink-topic
#                ||                                           |                     ||
#                ||                                           |                     ||
#                ||                                           \--> (p2-store)       ||
#                ||                                                                 ||
#                ||=================================================================||
#

# ===
# SOURCES
# ===

# Comma-separated list of IDs for source nodes.
sources.ids=source1,MySource

# ---
# Source nodes configuration
# ---

# Comma-separated list of source topics
source1.topics=test1,test2
MySource.topics=my-source-topic

# ===
# PROCESSORS
# ===

# Comma-separated list of IDs for processor nodes.
processors.ids=p1,p2

# ---
# Processor nodes configuration
# ---

# Processor Supplier class
# More info:
#   https://kafka.apache.org/0100/javadoc/org/apache/kafka/streams/processor/ProcessorSupplier.html
#
p1.supplier=ru.kiae.dkb.kafka.streams.processor.external.ExternalProcessorSupplier
p2.supplier=MyProcessorSupplier

# Processor Supplier configuration, if needed.
#
# Use prefix "processor." for parameter names:
#   <processorID>.processor.<parameter_name>
#
# Full set of available parameters depends on the supplier type.
#
# ExternalProcessorSupplier:
#   external.command -- command line to run external program for data processing
#     Example:
#     p1.processor.external.command=../099_myStage/runMyStage.sh --opt1 "value" arg1 arg2
#   eop.marker       -- end of processing marker, used in external program
#     Example:
#     p1.processor.eop.marker="\n" (default)
#     p1.processor.eop.marker='\u0000'
#     p1.processor.eop.marker=|

p1.processor.external.command=cat

# Topology links
# Comma-separated list of the upstream node (source or processor) IDs
p1.parents=source1
p2.parents=mySource,p1

# ===
# STATE STORES
# ===

# Comma-separated list of store IDs
stores.ids=p2-store

# Key/Value SerDe or data type class name.
# DEFAULT: java.lang.String
#
# For String Serde (same effect as String data type):
# p2-store.key.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
# p2-store.value.serde=org.apache.kafka.common.serialization.Serdes$StringSerde
#
# For String data type (same as String Serde):
# p2-store.key.serde=java.lang.String
# p2-store.value.serde=java.lang.String

# Comma-separated list of IDs of the processor nodes, connected to the given State Store
p2-store.processors=p2

# ===
# SINKS
# ===

# Comma-separated list of IDs for sink nodes
sinks.ids=sink1,sink2

# Name of the sink topic
sink1.topic=my-sink-topic
sink2.topic=another-sink-topic

# Topology links
# Comma-separated list of the upstream node (processor) IDs
sink1.parents=p1
sink2.parents=p2
