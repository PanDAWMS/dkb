============
* Stage 19 *
============

1. Description
-----------
Prepare data before uploading to ElasticSearch:
 * turn JSON keys to lower case
 * generate JSON with ES bulk API action information

Use ./run.sh to run stage with common configuration from
  /Utils/Elasticsearch/config/es

Use `--update` option to produce records intended to *update* data in ES,
  not replace.

2. Input
-----
Expects data in JSON format with special fields.
Required:
* '_id' (ES record identifier);
* '_type' (ES record type).

Optional:
* '_parent' (ES identifier for parent type record).
* '_update' (corresponding ES record should be "updated", not
             "inserted"/"indexed").

3. Output
------
JSON documents, one document per line:
{{{
 <action info>
 <data>
 <action info>
 <data>
 ...
}}}

4. Samples
-------
To produce regular (seamless NDJSON) samples, run:

  cat input/sample_name.ndjson | tr $'\n' $'\x1e' | \
    ./run.sh -E '' | tr -d $'\x1e' > output/sample_name.ndjson

Comment:
 * input samples can not be used (and output one -- saved) as-is
   due to the specific EOM marker (most of the stages use NEWLINE, which,
   being part of the output messages body, is not allowed here);
 * `tr` is a Unix utility to translate or delete characters (for details please
   refer to man pages);
 * output message body contains trailing NEWLINE, so RS is simply removed from
   the output stream (not replaced with another NEWLINE).

The 'output' directory contains following samples (in regular NDJSON format):

* with 2016 data:
  * tasks2016.ndjson
  * datasets2016.ndjson

* with 2018 data:
  * tasks2018.ndjson
  * datasets2018.ndjson

* extra samples:
  * <SAMPLE>.update.ndjson -- same as <SAMPLE>.ndjson, but generated with
                              '--update' option.

tasks* is the tasks' and input datasets' metadata.
datasets* is the output datasets' metadata.
